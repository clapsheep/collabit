# [01/13] Redis를 우리 프로젝트에 사용해야 하는 이유

- 오픈 소스 기반 고성능 키-값 저장소
- NoSQL 데이터베이스 중 하나
- 캐싱, 세션 관리, 메시지 브로커, 대기열 처리 등에 활용
- 메모리 내 데이터 저장으로 빠른 응답 속도를 제공하며 디스크에 데이터를 지속적으로 저장하여 데이터 손실을 방지
- 다양한 데이터 구조 지원, 문자열, 리스트, 해시, 집합, 정렬집합과 같은 데이터 타입을 다룰 수 있음
- Pub-Sub 메커니즘을 통한 메시지 브로커
- 클라이언트 간 메시지 전달 및 이벤트 기반 아키텍처에 활용
- Key-value 저장소중 1위

### 특징

- 인메모리 데이터베이스 : 데이터를 메모리에 저장해 빠른 응답 속도
- 다양한 데이터 타입
- 영속성 : 디스크에 데이터를 주기적으로 저장해 데이터 지속성 제공
- Pub-Sub 메시징 : 메시지 브로커로 사용
- 트랜잭션 싱글 스레드 → 안정성
- 클러스터링 : 데이터 샤딩, 레플리케이션을 통한 고가용성 및 확장성을 제공하는 클러스터 구성 가능
  - 샤딩 : 같은 테이블 스키마를 가진 데이터를 다수의 데이터베이스에 분산하여 저장하는 방법
- LRU 및 만료 시간

### 캐시(Cache)

- 한번 조회된 데이터를 미리 특정 공간에 저장해놓고 똑같은 요청이 발생하면 저장해둔 데이터를 제공해 빠르게 서비스 제공
- Redis Cache는 메모리단에 위치해 용량은 작지만 접근 속도가 빠름

## 활용사례

→ 운영중인 웹 서버에서 키-값 형태의 데이터 타입을 처리해야 하고 I/O가 빈번히 발생해 다른 저장 방식을 사용하면 효율이 떨어지는 경우에 사용

### 트위터

- 타임라인에서 15만명이 넘는 실시간 활동 사용자와 초당 30만 건이 넘는 타임라인 요청 응답 속도를 향상시키기 위해 Redis 사용
- 트위터 데이터센터의 레디스클러스터는 타임라인에 노출된 트윗의 정보를 리스트 형태로 약 800개 정도 캐싱
- 타임라인 요청이 발생하면 캐싱된 정보를 먼저 가져오고 이를 토대로 쿼리를 단순화해 데이터베이스에 접근하여 처리

### 주로 사용하는 곳

- 인증 토큰 저장
- API 캐싱 → 동일 여청에 대해 캐싱된 데이터 리턴
- 채팅
- 좋아요, 조회수 처리 → 댓글 번호를 key, 좋아요 누른 회원ID를 item 추가
- 일일 방문자수
- 최근 검색 목록 sorted set
- 출석 이벤트
- 랭킹
- 이벤트 알림

## 채팅 외부 브로커 비교

### **RabbitMQ**

- 다양한 비즈니스에 의한 복잡한 라우팅 설계에 적합한 메시지 브로커
- AMQP를 사용하여 지점 간 방법과 게시-구독 방법을 통해 메시지를 전달한다.
  - AMQP(Advanced Message Queuing Protocols): 애플리케이션간에 데이터를 주고받을 때, 메시지 미들웨어 브로커를 통해 데이터를 주고받을 수 있게 해주는 메시징 프로토콜
- 신뢰성 있는 메시지를 전송할 수 있기 때문에 정확한 요청-응답이 필요하거나, 트래픽은 작지만 장시간 실행되고 안정적인 작업이 필요한 경우에 사용할 수 있다.

### **Redis**

- 고성능 Key-Value 저장소 또는 메시지 브로커로 사용할 수 있는 인메모리 데이터 저장소이다.
- Pub/Sub 기능
  - 다른 메시지 브로커와 다르게 메시지 지속성이 없다.
    - 즉, 메시지를 전송한 후 해당 메시지는 삭제되고 Redis 어디에도 저장되지 않는다.
    - 따라서 channel에 구독하고 있지 않으면 메시지가 유실 될 수 있다. 또한, 채팅방의 채팅이 많아질 경우 채팅 순서가 보장되지 않을 수 있다.
    - 메시지 전송 신뢰성을 보장하지 않기 때문에 단점을 보완할 별도의 추가 구현(Redis Streams)이 필요할 수 있다.
- 실시간으로 빠르게 데이터 처리를 해야하는 서비스와 인메모리 데이터베이스로 인해 지속성이 중요하지 않고, 일정 수준의 손실을 처리할 수 있는 짧은 보존 메시지에 적합하다.

### **Kafka**

- 대량의 데이터를 저장하면서 높은 처리량이 필요한 곳에 적합한 메시지 브로커
- Pub/Sub 모델의 메시지 큐로 분산환경에 특화되어 있는 특징을 가지는 서버이다.
  - 다수의 서버가 하나의 서비스를 이루는 경우, kafka를 이용하여 분산처리를 하는데 각 서버가 통신하는 방식은 Pub/Sub을 이용한다.
  - 이 Pub/Sub 메시지들은 메시지 큐의 형태로 순차적으로 처리되며, 모든 메시지들은 로그로 처리된다.
  - 이 특성을 이용하면 서비스의 안정성을 확보할 수 있다.

⇒ 채팅 기록을 남길 거라면 Kafka, 아니라면 Redis

## 결론! 우리 프로젝트에 적용할 부분

- JWT 인증 토큰 저장 (Refresh Token)
- API 캐싱 → 동일 요청에 대해 캐싱된 데이터 리턴 (프로필)
- 게시판 좋아요, 조회수 처리 → 댓글 번호를 key, 좋아요 누른 회원ID를 item 추가
- 최근 검색 목록 sorted set → 이건 혹시 게시판에 검색 기능 있는 경우 활용 가능
- 랭킹 → 좋아요, 조회수 데이터를 기준으로 한 랭킹
- 이벤트 알림 → 리뷰나 채팅 알림을 띄운다면…
- 채팅 → Kafka가 더 적합하지 않을까? 이전 사람과의 채팅을 남길 거라면!

# [01/14] 설문에 필요한 문항 정리

김은영, 김소정(2016). “대학생 학습공동체 참여역량 척도 개발
및 타당화 연구”, 한국교육학연구 22(4), 87-113.

### 공감능력

- 다른 사람이 말하는 내용을 듣고 상대방의 생각을 이해할 수 있나요?
- 다른 사람의 기분이나 감정을 비교적 잘 파악하나요?
- 상대방의 입장을 고려하나요?
- 상대방의 기분이나 감정을 이해하나요?

### 경청능력

- 다른 사람과 이야기 할 때 상대방의 말을 집중해서 듣나요?
- 다른 사람의 의견을 경청하고 존중하나요?
- 다른 사람과 이야기 할 때 상대의 말을 끝까지 들어주나요?
- 의견을 교환할 때 자기 의견만을 내세우지 않나요?

### 표현능력

- 어떤 주제에 대한 자신의 견해를 정리할 수 있나요?
- 말하고자 하는 것을 적절한 용어를 사용하여 상대방에게 말할 수 있나요?
- 생각하는 바를 글과 말을 통해 정확하게 쓰거나 말할 수 있나요?
- 여러 사람 앞에서 생각을 정확히 전달할 수 있나요?

### 문제해결능력

- 문제해결을 위해 여러 각도에서 그 문제를 보려고 하나요?
- 중요도에 따라 여러 해결방법의 우선순위를 정하나요?
- 문제해결 방법을 체계적으로 평가하고 비교하나요?
- 문제해결 후 평가해보는 시간을 가지나요?

### 갈등해결능력

- 팀원 사이의 갈등을 중재하나요?
- 팀원과 의견이 달라도 상대의 말이 맞으면 받아들이나요?
- 팀원 사이에 의견이 다를 때 이를 조정하나요?
- 중요한 문제에 대해 팀원의 다양한 의견을 수렴하나요?

### 협업능력

- 팀에서맡은 부분을 끝까지 책임지고 해내나요?
- 프로젝트 수행 시 어려운 일이라도 솔선수범하나요?
- 팀원에게 어려운 일이 있을 때 팀원을 도와주나요?
- 팀에서 맡은 역할이 무엇인지 알고 있나요?

# [01/15] Redis로 좋아요 기능 구현을 위한 방법

- Redis는 캐시이기 때문에 RDB에 따로 저장할 필요가 있음
- Redis는 캐싱을 위해, RDB는 데이터의 영속성을 위해 필요함
- 따라서 RDB 필드에 존재해야 함

## 캐시 쓰기 전략 - Write Back 패턴

- 쓰기 작업은 항상 캐시에 수행하고 스케줄링을 통해 주기적으로 디비에 캐시 데이터를 옮겨줌
- 쓰기, 읽기가 자주 일어나고 응답속도가 중요한 기능에 사용할 수 있음
- 데이터 누락 처리가 필요하지만 좋아요 기능은 상대적으로 데이터 누락에 따른 문제가 덜함

## 캐시 읽기 전략 - Look Aside 패턴

- 캐시에서 읽을 수 있는 데이터는 캐시에서 읽고 캐시 미스 시 DB에서 읽음
- 데이터베이스, 캐시 모두에게서 데이터를 불러올 수 있어 안정성이 높

## 스케줄링

- 캐시에 쓰기 연산이 수행된 게시글이 생긴 경우 DB 동기화 대상이 됨
- 캐시에 존재하는 모든 데이터를 주기적으로 동기화해야 함
- 데이터 누락을 최소화하기 위해 데이터가 expired 되기 전 DB에 데이터를 옮겨야 함
- 스케줄링 작업 시간 및 expire 주기를 결정할 필요가 있다!

## 결론

- 아예 Redis를 안 쓴다면? → 데이터 유실이 없어짐! 대신 속도와 성능에서는 아쉬움.
- 우리의 프로젝트에서 좋아요 기능이 데이터 유실 vs 응답성 중 어떤게 더 중요한가를 고민해보아야 함
- 내 생각 → 만약 좋아요를 한 글을 모아보아야 하는 경우 데이터 유실을 최소화해야 하지만 우리 서비스의 경우 단순히 추천 알고리즘에만 포함(아직 확정은 아니지만..)되기 때문에 이 기능에서 빠른 응답성이 더 중요한 것 같다!

# [01/16] 프로젝트 관련 DB 테이블 설계

```
PROJECT { --프로젝트
    int code PK --고유번호
    string title --프로젝트명
  }

  PROJECT_INFO { --내가 등록한 프로젝트 (나 - 프로젝트)
	  int project_code FK
	  string user_code FK --설문제작자
	  int total
	  int participant --내가 만든 설문 참여자 수
	  --색깔 코드? int 1~5 자동으로 증가 (user_code)
  }

  --1. 내가 참여한 프로젝트의 기여자들 나-상대의 관계로 인해 중복이 가능한
  --2. 프로젝트의 기여자들인데 내가 등록한 시점 기준 처리
  PROJECT_CONTRIBUTOR { --프로젝트 기여자 (우리 프로젝트에 참여한 사람 목록, 나 포함)
    int project_code FK PK
    string id PK --깃헙 아이디
  }
```

## PROJECT_CONTRIBUTOR 테이블을 어떻게 설계할까?

### 1안 나 - 기여자

A라는 프로젝트에 대해서 등록한 사람과 설문 대상자 모두가 새로 등록된다.
이렇게 할 경우 필드가 중복될 수 있다.
4명이서 한 프로젝트에서 1번 사람이 등록하면 1-2, 1-3, 1-4가 등록되고, 2번 사람이 등록하면 또 다시 2-1, 2-3, 2-4가 등록된다.

### 2안 기여자

내가 등록한 시점과 기여자가 등록된 시점을 모두 기록하여 비교를 통해 내 설문 대상자를 확인한다.
이렇게 할 경우 중복을 막을 수 있지만 데이터를 읽어오고 비교하는 과정이 필요하다.
4명이서 한 프로젝트에서 1번 사람이 등록하면 1, 2, 3, 4번 사람이 모두 등록되고 이후 2번 사람이 등록하더라도 기존 멤버들은 등록되지 않는다. 혹시 이후 5번 사람이 참가한 뒤더라도 1, 2번 사람들의 설문에 5번 사람은 참가할 수 없도록 날짜를 비교하는 방식이다.

### 논의해볼 점

우리의 상황에 가장 적합한 선택은 무엇일까? 배포를 해야하므로 DB의 용량이나 성능이 한정되어 있는 상황. 또 프로젝트 기여자를 조회할 일은 많지만 등록할 일은 그렇게 많진 않다. 내일까지 충분히 고민해보고 결론을 내려야 할 것 같다.

# [01/17] 백엔드 규칙 설정

백엔드 규칙 14개를 정했는데 그 중 꼭 지키고 싶은 규칙을 정리해본다.

1. 의미 있는 메소드 이름
2. 디자인 패턴 적극 활용 : 싱글턴, 팩토리 등등 디자인 패턴 공부해서 사용하기
3. 예외처리 : 전역에서 예외를 관리하기
4. 로그 및 테스트 작성
5. 코드 리뷰 : 백엔드 팀원 중 2명이 리뷰를 달고난 뒤 PR Merge

# [01/20] 백엔드 개발 환경 구성

이번 프로젝트를 위해 필요한 의존성을 추가하였다.
- DB : MySQL, MongoDB, Redis
- Swagger
- JWT
```dependencies {
    // ===== Core Dependencies =====
    implementation 'org.springframework.boot:spring-boot-starter-data-jpa'
    implementation 'org.springframework.boot:spring-boot-starter-data-mongodb'
    implementation 'org.springframework.boot:spring-boot-starter-data-redis'
    implementation 'org.springframework.boot:spring-boot-starter-web'
    implementation 'org.springframework.boot:spring-boot-starter-websocket'

    // ===== Security & OAuth =====
    implementation 'org.springframework.boot:spring-boot-starter-oauth2-client'
    implementation 'org.springframework.boot:spring-boot-starter-security'

    // ===== JWT =====
    implementation 'io.jsonwebtoken:jjwt-api:0.11.5'
    runtimeOnly 'io.jsonwebtoken:jjwt-impl:0.11.5'
    runtimeOnly 'io.jsonwebtoken:jjwt-jackson:0.11.5'

    // ===== Swagger (API Documentation) =====
    implementation 'org.springdoc:springdoc-openapi-starter-webmvc-ui:2.1.0'

    // ===== Utilities =====
    compileOnly 'org.projectlombok:lombok'
    annotationProcessor 'org.projectlombok:lombok'

    // ===== Development Tools =====
    developmentOnly 'org.springframework.boot:spring-boot-devtools'

    // ===== Database Drivers =====
    runtimeOnly 'com.mysql:mysql-connector-j'

    // ===== Testing =====
    testImplementation 'org.springframework.boot:spring-boot-starter-test'
    testImplementation 'org.springframework.security:spring-security-test'
}
```

이중 MongoDB와 Redis는 처음 사용해본다.
NoSQL은 RDB와 달리 별도의 스키마를 만들지 않아도 괜찮다.
몽고디비 연결을 맡아서 했는데 클러스터를 사용하면 배포가 따로 필요 없다는 점이 편리하다고 느꼈다.
스키마 대신 도큐먼트에 데이터를 넣는 방식이라 설정이 생각보다 간단히 끝났다.

# [01/21] 백엔드 개발 시작
개발 환경을 마저 설정하고 작업을 시작했다.
채팅 기능을 개발하기 위해 Redis Pub/Sub과 WebSocket 설정을 마쳤다.
WebSocket만으로 채팅을 했을 때의 문제를 해결하기 위해 Redis를 메시지 브로커로서 사용하고자 한다.
"/pub", '/sub/"을 prefix로 설정하고 Redis와 연결을 하는데 의존성 문제가 발생했다.
이 문제를 해결하기 위해 많은 자료를 조사했다.
처음 에러는 Reactor Netty 버전 관련 문제였는데 build.gradle을 아무리 수정해도 문제가 해결되지 않았다.
결국은 저녁이 되어서야 문제가 해결되었는데 원인은 configureMessageBroker의 브로커 설정에 있었다.
STOMP 대신 SimpleBroker로 바꾸고 레디스 관련 설정 두 줄을 제거했더니 문제 없이 프로그램이 실행되었다.

# [01/22] 채팅방 생성 및 메시지 저장, 조회 로직 고민
먼저 채팅방을 생성할 때 사용자가 생성을 하고 첫 메시지를 보내야만 생성이 되도록 플로우를 수정하였다.
기존에는 생성하면 바로 생성하고 그 뒤에 메시지를 보내는 걸로 생각했지만 이게 더 UX에 좋다고 판단해 바꾸었다.
메시지 저장 및 조회를 할 때는 상대가 그 메시지를 읽었는지 여부와 그에 따라 읽지 않은 메시지 개수를 띄워주기로 했다.
또, 채팅방 리스트를 조회할 때 마지막 메시지가 보이고 메시지 도착 시간에 따라 채팅방을 정렬하도록 했다.
아직 캐싱을 따로 하지는 않기도 했고 MongoDB가 처음이라 어느 정도로 속도가 나올지는 잘 모르겠다.
혹시 성능이 너무 떨어진다면 나중에 다시 Redis로 캐싱하는 로직을 추가해보고자 한다.

# [01/23] 채팅 기능 최적화를 위한 고민
이전에는 로그인과 동시에 웹소켓에 연결시켜서 실시간으로 메시지를 업데이트하는 방법을 생각했었으나
이 방법에서 메모리를 많이 잡아먹는 걸 지양하자는 논의를 마친 뒤 로직을 수정하였다.
메모리를 덜 잡아먹게 하기 위해 채팅 페이지에 들어갔을 때만 웹소켓 연결을 시작한다.
또 현재 사용자가 어떤 페이지에 있냐에 따라서 해당 채팅방 내용만 실시간으로 오고 나머지는 리스트만 업데이트하는 방향을 생각했다.
리스트도 매 메시지마다 업데이트가 되는 건 별로인 것 같아서 고민을 해보고 있다.
이에 따라 API와 웹소켓 메시지를 분리해서 로직을 다시 구상했다.

# [01/24] git stash에 대한 고민
종종 로컬에서 pull을 할 때 커밋되지 않은 파일이 남아 있어 문제가 생기는 상황이 꽤 있었고,
이 문제를 방지하기 위해 stash를 남발해왔다.
오늘도 일부 파일을 push하고 현재 서버가 잘 실행되는지 확인하기 위해 stash 명령어를 사용했다.
서버 실행을 확인하고나서 다시 원래의 상태로 되돌리려는데 좀 어려움을 겪었다.
정말 stash를 해두어야 하는 상태가 아님에도 남발했더니 어떤 상태로 돌아가야 하는지 찾는게 어려웠다.
결국은 약 15분만에 문제를 해결하기는 했지만 이전에 작성해둔 많은 파일이 날아간다는 생각에 걱정이 되었다.
다음에는 꼭 필요한 순간에만 신중하게게 stash를 사용해야겠다.

# [01/31] 프로젝트 구현방식 변화
우리 서비스에는 Github API를 활용해 로그인한 유저가 참여한 레포지토리를 가져오는 기능이 있다.
기존에는 모든 걸 백엔드에서 처리하여 유저가 등록할 수 있는 레포지토리 목록을 백엔드 API를 통해 가져오도록 했지만,
오늘 점심시간에 논의를 거친 결과, 클라이언트단에서 Github API를 직접 호출하도록 했다.
외부 API 연결 자체는 어렵지 않았으나 반환되는 데이터의 양이 방대하여 이걸 어떻게 처리해야 하나 고민이 되었다.
특히 각 레포지토리의 Contributor를 확인하기 위해서는 각각 하나의 API를 호출해야 하는 상황이었다.
이에 따라 디자인에 변화를 주기로 했다.
프로젝트 등록 페이지는 기존에 카드 형태로 되어 있었지만 리스트로 바꾸고 디테일 페이지를 만들기로 했다.
즉, 데스크탑 기준으로 병렬라우팅을 적용해보기로 했다.

# [02/03] Next의 병렬라우팅
기존에 다른 팀원이 만들어둔 병렬라우팅을 참고하여 자료를 찾아가며 구현해보았다.
/project/create라는 주소에 병렬라우팅을 적용하기 위해 하위 폴더에 @list, @detail 폴더를 추가했다.
그리고 create 폴더 안에는 layout.tsx를 추가해 화면의 절반씩을 차지하도록 flex를 적용하였다.
@list, @detail 폴더 안에는 page.tsx를 추가했고 리스트에서 원하는 카드를 누르면 쿼리스트링을 통해 이름을 전달하는 방식으로 구현했다.
병렬라우팅을 적용했더니 이전보다 디자인이 더 깔끔해졌고 데스크탑과 모바일에서 차이를 두기도 더 쉬워졌다.
